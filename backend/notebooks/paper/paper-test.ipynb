{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "# Paper Generator\n",
    "This notebooks demonstrates the paper generation papeline we propose. We use langchain for interaction with the OpenAI API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prequisits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (0.1.16)\n",
      "Requirement already satisfied: langchain-core in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (0.1.46)\n",
      "Requirement already satisfied: langchain-community in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (0.0.32)\n",
      "Requirement already satisfied: langchain_openai in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (0.0.8)\n",
      "Requirement already satisfied: ipywidgets in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (8.1.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (3.9.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (0.1.47)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain_openai) (1.17.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipywidgets) (8.23.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipywidgets) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: decorator in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/philipp/Library/Caches/pypoetry/virtualenvs/backend-xXYcI_nD-py3.11/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-core langchain-community langchain_openai ipywidgets pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, display_pretty, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OPENAI_API_KEY = input(\"Enter your OpenAI API key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "NOUGAT_URL = input(\"Enter Nougat URL: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Please provide OpenAI API Key\")\n",
    "if not NOUGAT_URL:\n",
    "    raise ValueError(\"Please provide Nougat URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c5b8e0c2f44010a717dc1b9afff2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf', description='Upload Base')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be557be8b0e42e48b37d1d1bdd757b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf', description='Upload Similar', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uploader_base = widgets.FileUpload(\n",
    "    accept='.pdf',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=False,  # True to accept multiple files upload else False\n",
    "    description=\"Upload Base\"\n",
    ")\n",
    "display(uploader_base)\n",
    "\n",
    "uploader_similar = widgets.FileUpload(\n",
    "    accept='.pdf',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=True,  # True to accept multiple files upload else False\n",
    "    description=\"Upload Similar\"\n",
    ")\n",
    "display(uploader_similar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nougat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUGAT_URL: http://137.226.232.15:8503'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Uploaded file: sulayman_corona.pdf'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from requests import Response, post, get\n",
    "file = uploader_base.value[0]\n",
    "display(f'NOUGAT_URL: {NOUGAT_URL}')\n",
    "display(f'Uploaded file: {file.name}')\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "}\n",
    "response = post(NOUGAT_URL + \"/predict\",\n",
    "                            files={\"file\": file.content}, headers=headers)\n",
    "response.raise_for_status()\n",
    "if not response.ok:\n",
    "    raise Exception(\"Error parsing PDF to Markdown\")\n",
    "\n",
    "response = response.json()\n",
    "\n",
    "\n",
    "similar_papers = []\n",
    "sim_files = uploader_similar.value\n",
    "for file in sim_files:\n",
    "    response = post(NOUGAT_URL + \"/predict\",\n",
    "                                files={\"file\": file[\"content\"]}, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    if not response.ok:\n",
    "        raise Exception(\"Error parsing PDF to Markdown\")\n",
    "    similar_papers.append(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Research in time of COVID-19\"\n",
    "context = \"\\n\\n\\n\\n\".join(similar_papers)\n",
    "base_chapter = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "class Section(BaseModel):\n",
    "    title: str\n",
    "    description: Optional[str] = \"\"\n",
    "    subsections: Optional[List['Section']] = None\n",
    "class ToC(BaseModel):\n",
    "    sections: List[Section]\n",
    "    \n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=ToC)\n",
    "\n",
    "toc_template = \"\"\"\n",
    "You are a scientific researcher, an expert in crafting high-quality scientific documents.\n",
    "You're trained across a wide range of scientific disciplines, enabling you to provide\n",
    "specialized assistance across various topics.\n",
    "\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "\n",
    "Base: {base_chapter}\n",
    "\n",
    "Write the Table of Content for a paper with  the following topic: {topic}.\n",
    "You can use the base as a starting point.\n",
    "Use the context for information about the topic.\n",
    "\n",
    "\n",
    "Only output the generated section, no additional information.\n",
    "Make the output match the following object to generate a json later.\n",
    "class Section(BaseModel):\n",
    "    title: str\n",
    "    description: Optional[str] = None\n",
    "    subsections: Optional[List['Section']] = None\n",
    "class ToC(BaseModel):\n",
    "    sections: List[Section]\n",
    "\"\"\"\n",
    "\n",
    "toc_prompt = PromptTemplate.from_template(toc_template)\n",
    "\n",
    "toc_chain =  toc_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_response = toc_chain.invoke(input={\"topic\": topic, \"context\": context, \"base_chapter\": base_chapter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sections': [{'title': 'Introduction',\n",
       "   'description': 'Overview of the impacts of the COVID-19 pandemic on the global research landscape, setting the scene for the detailed analyses in subsequent sections.'},\n",
       "  {'title': 'Data and Methods',\n",
       "   'description': 'Description of the data sources, collection methods, and analytical techniques used to evaluate the impact of COVID-19 on research activities.'},\n",
       "  {'title': 'Impact on Research Output',\n",
       "   'subsections': [{'title': 'General Trends in Research Output',\n",
       "     'description': 'Analysis of overall changes in research output volume and quality across different scientific fields during the pandemic.'},\n",
       "    {'title': 'Field-Specific Impacts',\n",
       "     'description': 'Detailed examination of how specific scientific fields were affected in terms of research output and collaboration.'}]},\n",
       "  {'title': 'Changes in Research Collaboration',\n",
       "   'subsections': [{'title': 'Collaboration Patterns',\n",
       "     'description': 'Exploration of changes in research collaboration patterns, including intramural, national, and international collaborations.'},\n",
       "    {'title': 'Influence of Mobility Restrictions',\n",
       "     'description': 'Assessment of how travel and mobility restrictions influenced collaborative research efforts globally.'}]},\n",
       "  {'title': 'Role of Digital and Open Access Platforms',\n",
       "   'description': 'Investigation into how digital platforms and open access policies facilitated continued research dissemination and collaboration during lockdowns.'},\n",
       "  {'title': 'Gender and Geographical Disparities',\n",
       "   'description': 'Analysis of how the pandemic affected research productivity differently across gender lines and geographic locations.'},\n",
       "  {'title': 'Policy Implications and Recommendations',\n",
       "   'description': 'Discussion of the implications of study findings for science policy and recommendations for supporting research during global emergencies.'},\n",
       "  {'title': 'Conclusions',\n",
       "   'description': 'Summary of key findings, limitations of the study, and potential areas for future research.'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Introduction\n",
       "Overview of the impacts of the COVID-19 pandemic on the global research landscape, setting the scene for the detailed analyses in subsequent sections.\n",
       "# Data and Methods\n",
       "Description of the data sources, collection methods, and analytical techniques used to evaluate the impact of COVID-19 on research activities.\n",
       "# Impact on Research Output\n",
       "### General Trends in Research Output\n",
       "Analysis of overall changes in research output volume and quality across different scientific fields during the pandemic.\n",
       "### Field-Specific Impacts\n",
       "Detailed examination of how specific scientific fields were affected in terms of research output and collaboration.\n",
       "# Changes in Research Collaboration\n",
       "### Collaboration Patterns\n",
       "Exploration of changes in research collaboration patterns, including intramural, national, and international collaborations.\n",
       "### Influence of Mobility Restrictions\n",
       "Assessment of how travel and mobility restrictions influenced collaborative research efforts globally.\n",
       "# Role of Digital and Open Access Platforms\n",
       "Investigation into how digital platforms and open access policies facilitated continued research dissemination and collaboration during lockdowns.\n",
       "# Gender and Geographical Disparities\n",
       "Analysis of how the pandemic affected research productivity differently across gender lines and geographic locations.\n",
       "# Policy Implications and Recommendations\n",
       "Discussion of the implications of study findings for science policy and recommendations for supporting research during global emergencies.\n",
       "# Conclusions\n",
       "Summary of key findings, limitations of the study, and potential areas for future research.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def format_to_markdown(section, level=0):\n",
    "    # Markdown header levels\n",
    "    header = '#' * (level + 1)\n",
    "    # Start with the section title\n",
    "    markdown = f\"{header} {section['title']}\\n\"\n",
    "    # Add the section content if available\n",
    "    if section.get('description'):\n",
    "        markdown += f\"{section['description']}\\n\"\n",
    "    # Recursively format subsections if they exist\n",
    "    if section.get('subsections'):\n",
    "        for subsection in section['subsections']:\n",
    "            markdown += format_to_markdown(subsection, level + 2)\n",
    "    return markdown\n",
    "\n",
    "# Generate markdown for each top-level section\n",
    "markdown_output = \"\"\n",
    "for top_section in toc_response['sections']:\n",
    "    markdown_output += format_to_markdown(top_section)\n",
    "\n",
    "display(toc_response)\n",
    "display(Markdown(markdown_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sections\n",
    "We will now generate the sections based on the table of content above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_template = \"\"\"\n",
    "You are a scientific researcher, an expert in crafting high-quality scientific documents.\n",
    "You're trained across a wide range of scientific disciplines, enabling you to provide\n",
    "specialized assistance across various topics.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Base: {base_chapter}\n",
    "\n",
    "Already generated content: {generated_text}\n",
    "\n",
    "Write an {section} section for the following topic: {topic}.\n",
    "You can use the base section and the already generated content as a starting point.\n",
    "Use the context for information about the topic.\n",
    "\n",
    "Make the generated output latex. Only output the generated section, no additional information.\n",
    "\"\"\"\n",
    "\n",
    "section_prompt = PromptTemplate.from_template(toc_template)\n",
    "\n",
    "section_chain =  toc_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Introduction', 'description': 'Overview of the impacts of the COVID-19 pandemic on the global research landscape, setting the scene for the detailed analyses in subsequent sections.'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'subsections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m         subsection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m subsection_response\n\u001b[1;32m     11\u001b[0m         subsections\u001b[38;5;241m.\u001b[39mappend(subsection)\n\u001b[0;32m---> 12\u001b[0m section_resonse \u001b[38;5;241m=\u001b[39m section_chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: topic, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: context, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_chapter\u001b[39m\u001b[38;5;124m\"\u001b[39m: base_chapter, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43msubsections\u001b[49m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m\"\u001b[39m: section[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[1;32m     13\u001b[0m section[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m section_resonse\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subsections' is not defined"
     ]
    }
   ],
   "source": [
    "sections = toc_response['sections']\n",
    "\n",
    "for i, section in enumerate(sections):\n",
    "    print(section)\n",
    "    subsections = []\n",
    "    if hasattr(object, 'subsections'):\n",
    "        for j, subsection in enumerate(section[\"subsections\"]):\n",
    "            generated_text = subsection[\"generated_text\"] or \"\"\n",
    "            subsection_response = section_chain.invoke(input={\"topic\": topic, \"context\": context, \"base_chapter\": base_chapter, \"generated_text\": generated_text, \"section\": subsection[\"title\"]})\n",
    "            subsection[\"generated_text\"] = subsection_response\n",
    "            subsections.append(subsection)\n",
    "    section_resonse = section_chain.invoke(input={\"topic\": topic, \"context\": context, \"base_chapter\": base_chapter, \"generated_text\": \"\\n\\n\".join(subsections), \"section\": section[\"title\"]})\n",
    "    section[\"generated_text\"] = section_resonse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(sections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-xXYcI_nD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
